{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FN = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "you should use GPU but if it is busy then you always can fall back to your CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['THEANO_FLAGS'] = 'device=cpu,floatX=float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use indexing of tokens from [vocabulary-embedding](./vocabulary-embedding.ipynb) this does not clip the indexes of the words to `vocab_size`.\n",
    "\n",
    "Use the index of outside words to replace them with several `oov` words (`oov` , `oov0`, `oov1`, ...) that appear in the same description and headline. This will allow headline generator to replace the oov with the same word in the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FN0 = 'vocabulary-embedding'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "implement the \"simple\" model from http://arxiv.org/pdf/1512.01712v1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "you can start training from a pre-existing model. This allows you to run this notebooks many times, each time using different parameters and passing the end result of one run to be the input of the next.\n",
    "\n",
    "I've started with `maxlend=0` (see below) in which the description was ignored. I then moved to start with a high `LR` and the manually lowering it. I also started with `nflips=0` in which the original headlines is used as-is and slowely moved to `12` in which half the input headline was fliped with the predictions made by the model (the paper used fixed 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FN1 = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "input data (`X`) is made from `maxlend` description words followed by `eos`\n",
    "followed by headline words followed by `eos`\n",
    "if description is shorter than `maxlend` it will be left padded with `empty`\n",
    "if entire data is longer than `maxlen` it will be clipped and if it is shorter it will be right padded with empty.\n",
    "\n",
    "labels (`Y`) are the headline words followed by `eos` and clipped or padded to `maxlenh`\n",
    "\n",
    "In other words the input is made from a `maxlend` half in which the description is padded from the left\n",
    "and a `maxlenh` half in which `eos` is followed by a headline followed by another `eos` if there is enough space.\n",
    "\n",
    "The labels match only the second half and \n",
    "the first label matches the `eos` at the start of the second half (following the description in the first half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "maxlend=25 # 0 - if we dont want to use description at all\n",
    "maxlenh=25\n",
    "maxlen = maxlend + maxlenh\n",
    "rnn_size = 512 # must be same as 160330-word-gen\n",
    "rnn_layers = 3  # match FN1\n",
    "batch_norm=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "the out of the first `activation_rnn_size` nodes from the top LSTM layer will be used for activation and the rest will be used to select predicted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activation_rnn_size = 40 if maxlend else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "seed=42\n",
    "p_W, p_U, p_dense, p_emb, weight_decay = 0, 0, 0, 0, 0\n",
    "optimizer = 'adam'\n",
    "LR = 1e-4\n",
    "batch_size=64\n",
    "nflips=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#nb_train_samples = 30000\n",
    "#nb_val_samples = 3000\n",
    "nb_train_samples = 700\n",
    "nb_val_samples = 299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# read word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import cPickle as pickle\n",
    "import pickle\n",
    "\n",
    "with open('data/%s.pkl'%FN0, 'rb') as fp:\n",
    "    embedding, idx2word, word2idx, glove_idx2idx = pickle.load(fp)\n",
    "vocab_size, embedding_size = embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('data/%s.data.pkl'%FN0, 'rb') as fp:\n",
    "    X, Y = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nb_unknown_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples 999 999\n",
      "dimension of embedding space for words 100\n",
      "vocabulary size 40000 the last 10 words can be used as place holders for unknown/oov words\n",
      "total number of different words 62811 62811\n",
      "number of words outside vocabulary which we can substitue using glove similarity 6584\n",
      "numberof wordsthatwillbe regardedas unknonw(unk)/out-of-vocabulary(oov) 16227\n"
     ]
    }
   ],
   "source": [
    "print('number of examples',len(X),len(Y))\n",
    "print('dimension of embedding space for words',embedding_size)\n",
    "print('vocabulary size', vocab_size, 'the last %d words can be used as place holders for unknown/oov words'%nb_unknown_words)\n",
    "print('total number of different words',len(idx2word), len(word2idx))\n",
    "print('number of words outside vocabulary which we can substitue using glove similarity', len(glove_idx2idx))\n",
    "print('numberof wordsthatwillbe regardedas unknonw(unk)/out-of-vocabulary(oov)',len(idx2word)-vocab_size-len(glove_idx2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(nb_unknown_words):\n",
    "    idx2word[vocab_size-1-i] = '<%d>'%i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "when printing mark words outside vocabulary with `^` at their end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "oov0 = vocab_size-nb_unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(oov0, len(idx2word)):\n",
    "    idx2word[i] = idx2word[i]+'^'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(700, 700, 299, 299)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nb_val_samples)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=nb_val_samples, random_state=seed)\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "empty = 0\n",
    "eos = 1\n",
    "idx2word[empty] = '_'\n",
    "idx2word[eos] = '~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "import random, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prt(label, x):\n",
    "    print(label+':',)\n",
    "    for w in x:\n",
    "        print(idx2word[w],)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\n",
      "Minor\n",
      "Hotel\n",
      "Group\n",
      "to\n",
      "co-invest\n",
      "with\n",
      "Nakheel\n",
      "for\n",
      "first\n",
      "AVANI\n",
      "Hotel\n",
      "in\n",
      "Dubai\n",
      "\n",
      "D:\n",
      "Thailand-based^\n",
      "Minor\n",
      "Hotel\n",
      "Group\n",
      "(MHG),\n",
      "has\n",
      "announced\n",
      "a\n",
      "strategic\n",
      "partnership\n",
      "with\n",
      "Dubai-based\n",
      "Nakheel\n",
      "Group\n",
      "to\n",
      "co-invest\n",
      "and\n",
      "develop\n",
      "a\n",
      "500-key\n",
      "Avani\n",
      "hotel\n",
      "in\n",
      "Dubai,\n",
      "to\n",
      "be\n",
      "opened\n",
      "in\n",
      "2018.\n",
      "Avani\n",
      "Deira\n",
      "Dubai\n",
      "Hotel\n",
      "will\n",
      "be\n",
      "located\n",
      "in\n",
      "Deira\n",
      "Islands,\n",
      "a\n",
      "unique\n",
      "waterfront\n",
      "entertainment,\n",
      "tourist\n",
      "and\n",
      "residential\n",
      "destination\n",
      "being\n",
      "developed\n",
      "in\n",
      "alignment\n",
      "with\n",
      "Dubai\n",
      "Vision\n",
      "2020.\n",
      "Comprising^\n",
      "four\n",
      "islands\n",
      "situated\n",
      "adjacent\n",
      "to\n",
      "Dubai’s\n",
      "Deira\n",
      "district,\n",
      "with\n",
      "a\n",
      "total\n",
      "area\n",
      "of\n",
      "over\n",
      "15.3\n",
      "square\n",
      "kilometres,^\n",
      "Deira\n",
      "Islands,\n",
      "developed\n",
      "by\n",
      "Nakheel,\n",
      "will\n",
      "feature\n",
      "a\n",
      "variety\n",
      "of\n",
      "beachfront\n",
      "resorts,^\n",
      "hotels\n",
      "and\n",
      "residential\n",
      "communities,\n",
      "a\n",
      "shopping\n",
      "mall,\n",
      "a\n",
      "waterfront\n",
      "night\n",
      "market\n",
      "and\n",
      "an\n",
      "impressive\n",
      "amphitheatre^\n",
      "able\n",
      "to\n",
      "accommodate\n",
      "up\n",
      "to\n",
      "30,000\n",
      "people.\n",
      "The\n",
      "Avani\n",
      "hotel\n",
      "will\n",
      "be\n",
      "close\n",
      "to\n",
      "Dubai\n",
      "International\n",
      "Airport,\n",
      "with\n",
      "views\n",
      "of\n",
      "the\n",
      "Dubai\n",
      "skyline^\n",
      "and\n",
      "across\n",
      "the\n",
      "Arabian\n",
      "Gulf.^\n",
      "The\n",
      "new-build^\n",
      "hotel\n",
      "is\n",
      "the\n",
      "first\n",
      "of\n",
      "MHG’s\n",
      "vibrant\n",
      "Avani\n",
      "brand\n",
      "to\n",
      "be\n",
      "announced\n",
      "in\n",
      "the\n",
      "UAE.\n",
      "Blending^\n",
      "genuine\n",
      "hospitality\n",
      "and\n",
      "relaxed\n",
      "comfort\n",
      "with\n",
      "a\n",
      "passion\n",
      "for\n",
      "design,\n",
      "contemporary\n",
      "style\n",
      "and\n",
      "modern\n",
      "lifestyle\n",
      "essentials,\n",
      "Avani\n",
      "offers\n",
      "all\n",
      "the\n",
      "details\n",
      "that\n",
      "matter\n",
      "for\n",
      "a\n",
      "seamless\n",
      "stay\n",
      "that\n",
      "always\n",
      "leaves\n",
      "a\n",
      "great\n",
      "impression.\n",
      "From\n",
      "leisure\n",
      "time\n",
      "to\n",
      "productive\n",
      "business,\n",
      "family\n",
      "friendly\n",
      "attractions^\n",
      "and\n",
      "romantic\n",
      "gestures,\n",
      "the\n",
      "Avani\n",
      "experience\n",
      "is\n",
      "created\n",
      "with\n",
      "all\n",
      "guests’^\n",
      "needs\n",
      "in\n",
      "mind.\n",
      "Avani\n",
      "was\n",
      "launched\n",
      "by\n",
      "MHG\n",
      "in\n",
      "2011\n",
      "in\n",
      "response\n",
      "to\n",
      "an\n",
      "increasingly\n",
      "influential\n",
      "group\n",
      "of\n",
      "discerning\n",
      "travellers\n",
      "who\n",
      "appreciate\n",
      "good\n",
      "design\n",
      "and\n",
      "excellent\n",
      "service,\n",
      "but\n",
      "also\n",
      "demand\n",
      "great\n",
      "value.\n",
      "The\n",
      "brand\n",
      "currently\n",
      "has\n",
      "13\n",
      "properties\n",
      "in\n",
      "operation\n",
      "in\n",
      "Thailand,\n",
      "Sri\n",
      "Lanka,\n",
      "Vietnam,^\n",
      "Malaysia,\n",
      "the\n",
      "Seychelles,^\n",
      "Mozambique,\n",
      "Botswana,^\n",
      "Lesotho,^\n",
      "Namibia\n",
      "and\n",
      "Zambia,^\n",
      "with\n",
      "a\n",
      "pipeline\n",
      "of\n",
      "further\n",
      "openings.^\n",
      "“We\n",
      "are\n",
      "really\n",
      "excited\n",
      "to\n",
      "announce\n",
      "the\n",
      "launch\n",
      "of\n",
      "our\n",
      "Avani\n",
      "brand\n",
      "in\n",
      "the\n",
      "UAE\n",
      "and\n",
      "also\n",
      "to\n",
      "be\n",
      "entering\n",
      "into\n",
      "a\n",
      "new\n",
      "strategic\n",
      "partnership\n",
      "with\n",
      "Nakheel,\n",
      "such\n",
      "a\n",
      "well\n",
      "respected\n",
      "partner\n",
      "in\n",
      "the\n",
      "region,\n",
      "and\n",
      "one\n",
      "that\n",
      "we\n",
      "plan\n",
      "to\n",
      "enjoy\n",
      "a\n",
      "fruitful\n",
      "ongoing\n",
      "relationship\n",
      "with\n",
      "going\n",
      "forward.\n",
      "Deira\n",
      "Islands\n",
      "is\n",
      "an\n",
      "impressive\n",
      "project\n",
      "and\n",
      "we\n",
      "are\n",
      "very\n",
      "pleased\n",
      "to\n",
      "have\n",
      "the\n",
      "opportunity\n",
      "to\n",
      "introduce\n",
      "AVANI\n",
      "into\n",
      "the\n",
      "Dubai\n",
      "market\n",
      "in\n",
      "this\n",
      "new\n",
      "development,”\n",
      "commented\n",
      "Dillip^\n",
      "Rajakarier,\n",
      "CEO,\n",
      "Minor\n",
      "Hotel\n",
      "Group.\n",
      "Ali\n",
      "Rashid\n",
      "Lootah^\n",
      ",\n",
      "Chairman,\n",
      "Nakheel\n",
      ",\n",
      "said:\n",
      "“Our\n",
      "partnership\n",
      "with\n",
      "MHG\n",
      "is\n",
      "yet\n",
      "another\n",
      "milestone\n",
      "for\n",
      "our\n",
      "growing\n",
      "hospitality\n",
      "business,\n",
      "and\n",
      "highlights\n",
      "our\n",
      "commitment\n",
      "to\n",
      "creating\n",
      "new\n",
      "tourism\n",
      "concepts\n",
      "in\n",
      "line\n",
      "with\n",
      "the\n",
      "Government\n",
      "of\n",
      "Dubai’s\n",
      "tourism\n",
      "vision\n",
      "for\n",
      "2021.\n",
      "Our\n",
      "strategy\n",
      "is\n",
      "to\n",
      "join\n",
      "forces\n",
      "with\n",
      "international\n",
      "partners\n",
      "who\n",
      "are\n",
      "serious\n",
      "about\n",
      "being\n",
      "part\n",
      "of\n",
      "Deira\n",
      "Islands,\n",
      "and\n",
      "then\n",
      "bring\n",
      "a\n",
      "range\n",
      "of\n",
      "new,\n",
      "international\n",
      "brands\n",
      "to\n",
      "this\n",
      "new\n",
      "waterfront\n",
      "city.\"\n",
      "MHG\n",
      "currently\n",
      "has\n",
      "a\n",
      "portfolio\n",
      "of\n",
      "nine\n",
      "hotels\n",
      "in\n",
      "the\n",
      "UAE\n",
      "across\n",
      "three\n",
      "of\n",
      "its\n",
      "brands\n",
      "–\n",
      "Anantara,\n",
      "PER^\n",
      "AQUUM^\n",
      "and\n",
      "Oaks.^\n",
      "A\n",
      "hotel\n",
      "owner,\n",
      "operator\n",
      "and\n",
      "investor,\n",
      "MHG\n",
      "has\n",
      "134\n",
      "hotels\n",
      "and\n",
      "resorts\n",
      "in\n",
      "22\n",
      "countries\n",
      "across\n",
      "Asia\n",
      "Pacific,\n",
      "the\n",
      "Middle\n",
      "East,\n",
      "Europe,\n",
      "South\n",
      "America,\n",
      "Africa\n",
      "and\n",
      "the\n",
      "Indian\n",
      "Ocean.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 334\n",
    "prt('H',Y_train[i])\n",
    "prt('D',X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\n",
      "Why\n",
      "Are\n",
      "the\n",
      "Brightest^\n",
      "Stars\n",
      "on\n",
      "Broadway\n",
      "Sharing\n",
      "Their\n",
      "Secrets\n",
      "of\n",
      "Success\n",
      "With\n",
      "This\n",
      "15-Year-Old^\n",
      "Local\n",
      "Greenville\n",
      "Podcaster?^\n",
      "\n",
      "D:\n",
      "GREENVILLE,\n",
      "S.C.\n",
      ",\n",
      "Sept.\n",
      "17,\n",
      "2015\n",
      "/PRNewswire/\n",
      "--\n",
      "Many\n",
      "young\n",
      "performers\n",
      "have\n",
      "dreams\n",
      "of\n",
      "making\n",
      "it\n",
      "to\n",
      "the\n",
      "bright\n",
      "lights\n",
      "of\n",
      "Broadway\n",
      "someday,\n",
      "but\n",
      "few\n",
      "have\n",
      "taken\n",
      "destiny^\n",
      "into\n",
      "their\n",
      "own\n",
      "hands\n",
      "like\n",
      "15-year-old\n",
      "Eryn\n",
      "Woo\n",
      "of\n",
      "Greenville,^\n",
      "South\n",
      "Carolina\n",
      ".\n",
      "Woo\n",
      "interviews\n",
      "actors,\n",
      "directors,\n",
      "playwrights,^\n",
      "talent\n",
      "agents\n",
      "and\n",
      "others\n",
      "from\n",
      "the\n",
      "industry\n",
      "on\n",
      "her\n",
      "podcast\n",
      "at\n",
      "http://www.goingforbroadway.com\n",
      ".\n",
      "Photo\n",
      "-\n",
      "http://photos.prnewswire.com/prnh/20150916/267181\n",
      "Photo\n",
      "-\n",
      "http://photos.prnewswire.com/prnh/20150916/267453^\n",
      "Woo\n",
      "asks\n",
      "insightful\n",
      "questions\n",
      "about\n",
      "all\n",
      "aspects\n",
      "of\n",
      "each\n",
      "guest's\n",
      "story.\n",
      "She\n",
      "delves^\n",
      "into\n",
      "the\n",
      "details\n",
      "of\n",
      "the\n",
      "chain\n",
      "of\n",
      "events\n",
      "that\n",
      "led\n",
      "them\n",
      "to\n",
      "their\n",
      "successful\n",
      "debuts\n",
      "on\n",
      "Broadway\n",
      "as\n",
      "well\n",
      "as\n",
      "the\n",
      "day-to-day\n",
      "rituals\n",
      "that\n",
      "help\n",
      "keep\n",
      "them\n",
      "stage-ready.^\n",
      "Woo's\n",
      "determination\n",
      "to\n",
      "gain\n",
      "a\n",
      "deep\n",
      "understanding\n",
      "of\n",
      "her\n",
      "guests\n",
      "is\n",
      "showcased\n",
      "in\n",
      "the\n",
      "thoughtfulness\n",
      "of\n",
      "her\n",
      "questions.\n",
      "Each\n",
      "guest\n",
      "interview\n",
      "has\n",
      "a\n",
      "different\n",
      "theme\n",
      "that\n",
      "Woo\n",
      "highlights\n",
      "for\n",
      "her\n",
      "followers.\n",
      "Topics\n",
      "like\n",
      "\"How\n",
      "to\n",
      "Achieve\n",
      "Your\n",
      "Dreams\",\n",
      "\"Understanding\n",
      "What\n",
      "You're\n",
      "Good\n",
      "At\"\n",
      "and\n",
      "\"Learning^\n",
      "to\n",
      "Subdue^\n",
      "Your\n",
      "Fears\"\n",
      "have\n",
      "been\n",
      "recorded\n",
      "on\n",
      "her\n",
      "podcast\n",
      "available\n",
      "on\n",
      "iTunes.\n",
      "Woo\n",
      "asserts\n",
      "herself\n",
      "as\n",
      "a\n",
      "virtual\n",
      "pied^\n",
      "piper\n",
      "for\n",
      "other\n",
      "young\n",
      "hopefuls\n",
      "who\n",
      "listen\n",
      "to\n",
      "her\n",
      "podcast\n",
      "and\n",
      "read\n",
      "her\n",
      "blog,\n",
      "enticing^\n",
      "and\n",
      "inspiring\n",
      "those\n",
      "around\n",
      "her\n",
      "with\n",
      "a\n",
      "yearning\n",
      "that\n",
      "is\n",
      "almost\n",
      "palpable.\n",
      "Broadway\n",
      "stars\n",
      "like\n",
      "Amelia\n",
      "Cormack^\n",
      ",\n",
      "currently\n",
      "starring\n",
      "in\n",
      "Kinky^\n",
      "Boots,^\n",
      "Rachel\n",
      "Izen\n",
      ",\n",
      "formerly\n",
      "in\n",
      "the\n",
      "cast\n",
      "of\n",
      "Mary\n",
      "Poppins\n",
      "and\n",
      "now\n",
      "in\n",
      "Les^\n",
      "Miserables,\n",
      "and\n",
      "Chante\n",
      "Carmel^\n",
      "of\n",
      "Motown\n",
      "the\n",
      "Musical,^\n",
      "are\n",
      "a\n",
      "few\n",
      "of\n",
      "the\n",
      "high-profile\n",
      "guests\n",
      "that\n",
      "have\n",
      "sat\n",
      "for\n",
      "interviews\n",
      "with\n",
      "Woo.^\n",
      "\"From\n",
      "the\n",
      "very\n",
      "beginning,\n",
      "I\n",
      "wanted\n",
      "this\n",
      "podcast\n",
      "to\n",
      "be\n",
      "a\n",
      "source\n",
      "of\n",
      "information\n",
      "not\n",
      "available\n",
      "anywhere\n",
      "else,\n",
      "as\n",
      "well\n",
      "as\n",
      "something\n",
      "that\n",
      "my\n",
      "listeners\n",
      "could\n",
      "find\n",
      "support\n",
      "and\n",
      "encouragement\n",
      "in,\"^\n",
      "Woo\n",
      "says.\n",
      "\"Since^\n",
      "I\n",
      "am\n",
      "on\n",
      "this\n",
      "same\n",
      "journey\n",
      "as\n",
      "the\n",
      "majority\n",
      "of\n",
      "my\n",
      "audience,\n",
      "the\n",
      "podcast\n",
      "allows\n",
      "me\n",
      "to\n",
      "engage\n",
      "with\n",
      "listeners\n",
      "and\n",
      "guests…and\n",
      "I'm\n",
      "excited\n",
      "by\n",
      "the\n",
      "response\n",
      "so\n",
      "far\n",
      "and\n",
      "what's\n",
      "in\n",
      "store\n",
      "of\n",
      "the\n",
      "future!\"\n",
      "Even\n",
      "at\n",
      "a\n",
      "young\n",
      "age,\n",
      "Woo\n",
      "has\n",
      "performed\n",
      "in\n",
      "multiple\n",
      "productions\n",
      "already,\n",
      "and\n",
      "the\n",
      "podcast\n",
      "is\n",
      "quickly\n",
      "expanding\n",
      "her\n",
      "knowledge\n",
      "along\n",
      "with\n",
      "her\n",
      "listeners.^\n",
      "To\n",
      "download\n",
      "the\n",
      "podcast\n",
      "directly,^\n",
      "visit\n",
      "the\n",
      "iTunes\n",
      "website\n",
      "link:^\n",
      "https://itunes.apple.com/us/podcast/going-for-broadway-podcast/id1035487954^\n",
      "About\n",
      "Eryn\n",
      "Woo\n",
      ":\n",
      "Eryn\n",
      "Woo\n",
      ",\n",
      "15,\n",
      "is\n",
      "an\n",
      "aspiring\n",
      "actress\n",
      "with\n",
      "dreams\n",
      "to\n",
      "make\n",
      "it\n",
      "to\n",
      "Broadway\n",
      "and\n",
      "beyond.\n",
      "She\n",
      "has\n",
      "performed\n",
      "in\n",
      "many\n",
      "plays\n",
      "and\n",
      "musicals^\n",
      "in\n",
      "her\n",
      "hometown\n",
      "of\n",
      "Greenville\n",
      ",\n",
      "South\n",
      "Carolina.\n",
      "Woo\n",
      "hosts\n",
      "a\n",
      "weekly\n",
      "podcast\n",
      "on\n",
      "which\n",
      "she\n",
      "interviews\n",
      "actors\n",
      "and\n",
      "industry-insiders\n",
      "to\n",
      "gain\n",
      "insight\n",
      "into\n",
      "how\n",
      "they\n",
      "achieved\n",
      "success\n",
      "on\n",
      "and\n",
      "around\n",
      "the\n",
      "stage\n",
      "in\n",
      "an\n",
      "effort\n",
      "to\n",
      "propel^\n",
      "her\n",
      "listeners\n",
      "and\n",
      "her\n",
      "aspirations^\n",
      "to\n",
      "make\n",
      "it\n",
      "themselves.\n",
      "For\n",
      "more\n",
      "information,\n",
      "visit\n",
      "the\n",
      "website:\n",
      "http://www.goingforbroadway.com\n",
      "Media\n",
      "Contact:\n",
      "Name:\n",
      "Edmund\n",
      "Woo\n",
      "Phone:\n",
      "864^\n",
      "363\n",
      "6644^\n",
      "Email\n",
      "To\n",
      "view\n",
      "the\n",
      "original\n",
      "version\n",
      "on\n",
      "PR\n",
      "Newswire,\n",
      "visit:\n",
      "http://www.prnewswire.com/news-releases/why-are-the-brightest-stars-on-broadway-sharing-their-secrets-of-success-with-this-15-year-old-local-greenville-podcaster-300144777.html^\n",
      "SOURCE\n",
      "Eryn\n",
      "Woo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#i = 334\n",
    "i = 100\n",
    "prt('H',Y_test[i])\n",
    "prt('D',X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector, Merge\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# seed weight initialization\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "regularizer = l2(weight_decay) if weight_decay else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "start with a standard stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size,\n",
    "                    input_length=maxlen,\n",
    "                    W_regularizer=regularizer, dropout=p_emb, weights=[embedding], mask_zero=True,\n",
    "                    name='embedding_1'))\n",
    "for i in range(rnn_layers):\n",
    "    lstm = LSTM(rnn_size, return_sequences=True, # batch_norm=batch_norm,\n",
    "                W_regularizer=regularizer, U_regularizer=regularizer,\n",
    "                b_regularizer=regularizer, dropout_W=p_W, dropout_U=p_U,\n",
    "                name='lstm_%d'%(i+1)\n",
    "                  )\n",
    "    model.add(lstm)\n",
    "    model.add(Dropout(p_dense,name='dropout_%d'%(i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A special layer that reduces the input just to its headline part (second half).\n",
    "For each word in this part it concatenate the output of the previous layer (RNN)\n",
    "with a weighted average of the outputs of the description part.\n",
    "In this only the last `rnn_size - activation_rnn_size` are used from each output.\n",
    "The first `activation_rnn_size` output is used to computer the weights for the averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda\n",
    "import keras.backend as K\n",
    "\n",
    "def simple_context(X, mask, n=activation_rnn_size, maxlend=maxlend, maxlenh=maxlenh):\n",
    "    desc, head = X[:,:maxlend,:], X[:,maxlend:,:]\n",
    "    head_activations, head_words = head[:,:,:n], head[:,:,n:]\n",
    "    desc_activations, desc_words = desc[:,:,:n], desc[:,:,n:]\n",
    "    \n",
    "    # RTFM http://deeplearning.net/software/theano/library/tensor/basic.html#theano.tensor.batched_tensordot\n",
    "    # activation for every head word and every desc word\n",
    "    activation_energies = K.batch_dot(head_activations, desc_activations, axes=(2,2))\n",
    "    # make sure we dont use description words that are masked out\n",
    "    activation_energies = activation_energies + -1e20*K.expand_dims(1.-K.cast(mask[:, :maxlend],'float32'),1)\n",
    "    \n",
    "    # for every head word compute weights for every desc word\n",
    "    activation_energies = K.reshape(activation_energies,(-1,maxlend))\n",
    "    activation_weights = K.softmax(activation_energies)\n",
    "    activation_weights = K.reshape(activation_weights,(-1,maxlenh,maxlend))\n",
    "\n",
    "    # for every head word compute weighted average of desc words\n",
    "    desc_avg_word = K.batch_dot(activation_weights, desc_words, axes=(2,1))\n",
    "    return K.concatenate((desc_avg_word, head_words))\n",
    "\n",
    "\n",
    "class SimpleContext(Lambda):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(SimpleContext, self).__init__(simple_context,**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return input_mask[:, maxlend:]\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        nb_samples = input_shape[0]\n",
    "        n = 2*(rnn_size - activation_rnn_size)\n",
    "        return (nb_samples, maxlenh, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if activation_rnn_size:\n",
    "    model.add(SimpleContext(name='simplecontext_1'))\n",
    "model.add(TimeDistributed(Dense(vocab_size,\n",
    "                                W_regularizer=regularizer, b_regularizer=regularizer,\n",
    "                                name = 'timedistributed_1')))\n",
    "model.add(Activation('softmax', name='activation_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop # usually I prefer Adam but article used rmsprop\n",
    "# opt = Adam(lr=LR)  # keep calm and reduce learning rate\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// new Audio(\"http://www.soundjay.com/button/beep-09.wav\").play ()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// new Audio(\"http://www.soundjay.com/button/beep-09.wav\").play ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr,np.float32(LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def str_shape(x):\n",
    "    return 'x'.join(map(str,x.shape))\n",
    "    \n",
    "def inspect_model(model):\n",
    "    for i,l in enumerate(model.layers):\n",
    "        print(i, 'cls=%s name=%s'%(type(l).__name__, l.name))\n",
    "        weights = l.get_weights()\n",
    "        for weight in weights:\n",
    "            print(str_shape(weight),)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cls=Embedding name=embedding_1\n",
      "40000x100\n",
      "\n",
      "1 cls=LSTM name=lstm_1\n",
      "100x512\n",
      "512x512\n",
      "512\n",
      "100x512\n",
      "512x512\n",
      "512\n",
      "100x512\n",
      "512x512\n",
      "512\n",
      "100x512\n",
      "512x512\n",
      "512\n",
      "\n",
      "2 cls=Dropout name=dropout_1\n",
      "\n",
      "3 cls=LSTM name=lstm_2\n",
      "512x512\n",
      "512x512\n",
      "512\n",
      "512x512\n",
      "512x512\n",
      "512\n",
      "512x512\n",
      "512x512\n",
      "512\n",
      "512x512\n",
      "512x512\n",
      "512\n",
      "\n",
      "4 cls=Dropout name=dropout_2\n",
      "\n",
      "5 cls=LSTM name=lstm_3\n",
      "512x512\n",
      "512x512\n",
      "512\n",
      "512x512\n",
      "512x512\n",
      "512\n",
      "512x512\n",
      "512x512\n",
      "512\n",
      "512x512\n",
      "512x512\n",
      "512\n",
      "\n",
      "6 cls=Dropout name=dropout_3\n",
      "\n",
      "7 cls=SimpleContext name=simplecontext_1\n",
      "\n",
      "8 cls=TimeDistributed name=timedistributed_1\n",
      "944x40000\n",
      "40000\n",
      "\n",
      "9 cls=Activation name=activation_1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if FN1 and os.path.exists('data/%s.hdf5'%FN1):\n",
    "    model.load_weights('data/%s.hdf5'%FN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lpadd(x, maxlend=maxlend, eos=eos):\n",
    "    \"\"\"left (pre) pad a description to maxlend and then add eos.\n",
    "    The eos is the input to predicting the first word in the headline\n",
    "    \"\"\"\n",
    "    assert maxlend >= 0\n",
    "    if maxlend == 0:\n",
    "        return [eos]\n",
    "    n = len(x)\n",
    "    if n > maxlend:\n",
    "        x = x[-maxlend:]\n",
    "        n = maxlend\n",
    "    return [empty]*(maxlend-n) + x + [eos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "samples = [lpadd([3]*26)]\n",
    "# pad from right (post) so the first maxlend will be description followed by headline\n",
    "data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(data[:,maxlend] == eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 50), <map at 0x7f1316049ef0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape,map(len, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 40000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict(data, verbose=0, batch_size=1)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sample generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "this section is only used to generate examples. you can skip it if you just want to understand how the training works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# variation to https://github.com/ryankiros/skip-thoughts/blob/master/decoding/search.py\n",
    "def beamsearch(predict, start=[empty]*maxlend + [eos],\n",
    "               k=1, maxsample=maxlen, use_unk=True, empty=empty, eos=eos, temperature=1.0):\n",
    "    \"\"\"return k samples (beams) and their NLL scores, each sample is a sequence of labels,\n",
    "    all samples starts with an `empty` label and end with `eos` or truncated to length of `maxsample`.\n",
    "    You need to supply `predict` which returns the label probability of each sample.\n",
    "    `use_unk` allow usage of `oov` (out-of-vocabulary) label in samples\n",
    "    \"\"\"\n",
    "    def sample(energy, n, temperature=temperature):\n",
    "        \"\"\"sample at most n elements according to their energy\"\"\"\n",
    "        n = min(n,len(energy))\n",
    "        prb = np.exp(-np.array(energy) / temperature )\n",
    "        res = []\n",
    "        for i in xrange(n):\n",
    "            z = np.sum(prb)\n",
    "            r = np.argmax(np.random.multinomial(1, prb/z, 1))\n",
    "            res.append(r)\n",
    "            prb[r] = 0. # make sure we select each element only once\n",
    "        return res\n",
    "\n",
    "    dead_k = 0 # samples that reached eos\n",
    "    dead_samples = []\n",
    "    dead_scores = []\n",
    "    live_k = 1 # samples that did not yet reached eos\n",
    "    live_samples = [list(start)]\n",
    "    live_scores = [0]\n",
    "\n",
    "    while live_k:\n",
    "        # for every possible live sample calc prob for every possible label \n",
    "        probs = predict(live_samples, empty=empty)\n",
    "\n",
    "        # total score for every sample is sum of -log of word prb\n",
    "        cand_scores = np.array(live_scores)[:,None] - np.log(probs)\n",
    "        cand_scores[:,empty] = 1e20\n",
    "        if not use_unk:\n",
    "            for i in range(nb_unknown_words):\n",
    "                cand_scores[:,vocab_size - 1 - i] = 1e20\n",
    "        live_scores = list(cand_scores.flatten())\n",
    "        \n",
    "\n",
    "        # find the best (lowest) scores we have from all possible dead samples and\n",
    "        # all live samples and all possible new words added\n",
    "        scores = dead_scores + live_scores\n",
    "        ranks = sample(scores, k)\n",
    "        n = len(dead_scores)\n",
    "        ranks_dead = [r for r in ranks if r < n]\n",
    "        ranks_live = [r - n for r in ranks if r >= n]\n",
    "        \n",
    "        dead_scores = [dead_scores[r] for r in ranks_dead]\n",
    "        dead_samples = [dead_samples[r] for r in ranks_dead]\n",
    "        \n",
    "        live_scores = [live_scores[r] for r in ranks_live]\n",
    "\n",
    "        # append the new words to their appropriate live sample\n",
    "        voc_size = probs.shape[1]\n",
    "        live_samples = [live_samples[r//voc_size]+[r%voc_size] for r in ranks_live]\n",
    "\n",
    "        # live samples that should be dead are...\n",
    "        # even if len(live_samples) == maxsample we dont want it dead because we want one\n",
    "        # last prediction out of it to reach a headline of maxlenh\n",
    "        zombie = [s[-1] == eos or len(s) > maxsample for s in live_samples]\n",
    "        \n",
    "        # add zombies to the dead\n",
    "        dead_samples += [s for s,z in zip(live_samples,zombie) if z]\n",
    "        dead_scores += [s for s,z in zip(live_scores,zombie) if z]\n",
    "        dead_k = len(dead_samples)\n",
    "        # remove zombies from the living \n",
    "        live_samples = [s for s,z in zip(live_samples,zombie) if not z]\n",
    "        live_scores = [s for s,z in zip(live_scores,zombie) if not z]\n",
    "        live_k = len(live_samples)\n",
    "\n",
    "    return dead_samples + live_samples, dead_scores + live_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python-Levenshtein-0.12.0.tar.gz (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 4.0MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages (from python-Levenshtein)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Running setup.py bdist_wheel for python-Levenshtein ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/carnd/.cache/pip/wheels/c0/83/e9/b2cc2876e175d04091caf4e9f5de564ff2503b1f1885e7c3ba\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.12.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def keras_rnn_predict(samples, empty=empty, model=model, maxlen=maxlen):\n",
    "    \"\"\"for every sample, calculate probability for every possible label\n",
    "    you need to supply your RNN model and maxlen - the length of sequences it can handle\n",
    "    \"\"\"\n",
    "    sample_lengths = map(len, samples)\n",
    "    assert all(l > maxlend for l in sample_lengths)\n",
    "    assert all(l[maxlend] == eos for l in samples)\n",
    "    # pad from right (post) so the first maxlend will be description followed by headline\n",
    "    data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    probs = model.predict(data, verbose=0, batch_size=batch_size)\n",
    "    return np.array([prob[sample_length-maxlend-1] for prob, sample_length in zip(probs, sample_lengths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vocab_fold(xs):\n",
    "    \"\"\"convert list of word indexes that may contain words outside vocab_size to words inside.\n",
    "    If a word is outside, try first to use glove_idx2idx to find a similar word inside.\n",
    "    If none exist then replace all accurancies of the same unknown word with <0>, <1>, ...\n",
    "    \"\"\"\n",
    "    xs = [x if x < oov0 else glove_idx2idx.get(x,x) for x in xs]\n",
    "    # the more popular word is <0> and so on\n",
    "    outside = sorted([x for x in xs if x >= oov0])\n",
    "    # if there are more than nb_unknown_words oov words then put them all in nb_unknown_words-1\n",
    "    outside = dict((x,vocab_size-1-min(i, nb_unknown_words-1)) for i, x in enumerate(outside))\n",
    "    xs = [outside.get(x,x) for x in xs]\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vocab_unfold(desc,xs):\n",
    "    # assume desc is the unfolded version of the start of xs\n",
    "    unfold = {}\n",
    "    for i, unfold_idx in enumerate(desc):\n",
    "        fold_idx = xs[i]\n",
    "        if fold_idx >= oov0:\n",
    "            unfold[fold_idx] = unfold_idx\n",
    "    return [unfold.get(x,x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import Levenshtein\n",
    "\n",
    "def gensamples(skips=2, k=10, batch_size=batch_size, short=True, temperature=1., use_unk=True):\n",
    "    i = random.randint(0,len(X_test)-1)\n",
    "    print('HEAD:',' '.join(idx2word[w] for w in Y_test[i][:maxlenh]))\n",
    "    print('DESC:',' '.join(idx2word[w] for w in X_test[i][:maxlend]))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    print('HEADS:')\n",
    "    x = X_test[i]\n",
    "    samples = []\n",
    "    if maxlend == 0:\n",
    "        skips = [0]\n",
    "    else:\n",
    "        skips = range(min(maxlend,len(x)), max(maxlend,len(x)), abs(maxlend - len(x)) // skips + 1)\n",
    "    for s in skips:\n",
    "        start = lpadd(x[:s])\n",
    "        fold_start = vocab_fold(start)\n",
    "        sample, score = beamsearch(predict=keras_rnn_predict, start=fold_start, k=k, temperature=temperature, use_unk=use_unk)\n",
    "        assert all(s[maxlend] == eos for s in sample)\n",
    "        samples += [(s,start,scr) for s,scr in zip(sample,score)]\n",
    "\n",
    "    samples.sort(key=lambda x: x[-1])\n",
    "    codes = []\n",
    "    for sample, start, score in samples:\n",
    "        code = ''\n",
    "        words = []\n",
    "        sample = vocab_unfold(start, sample)[len(start):]\n",
    "        for w in sample:\n",
    "            if w == eos:\n",
    "                break\n",
    "            words.append(idx2word[w])\n",
    "            code += chr(w//(256*256)) + chr((w//256)%256) + chr(w%256)\n",
    "        if short:\n",
    "            distance = min([100] + [-Levenshtein.jaro(code,c) for c in codes])\n",
    "            if distance > -0.6:\n",
    "                print(score, ' '.join(words))\n",
    "        #         print '%s (%.2f) %f'%(' '.join(words), score, distance)\n",
    "        else:\n",
    "                print(score, ' '.join(words))\n",
    "        codes.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: Corrie^ live exclusive:^ Kevin,^ Tim,^ Sally plot injects^ ‘humour’^\n",
      "DESC: Watch this exclusive interview with Michael Le Vell^ and Brooke Vincent talking to stv.tv^ about the Tim/Sally/Kevin^ ‘love^ triangle’^ storyline that will inject some light-hearted^\n",
      "HEADS:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 1 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f97810ccf9bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgensamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskips\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-a3e74d9ef100>\u001b[0m in \u001b[0;36mgensamples\u001b[0;34m(skips, k, batch_size, short, temperature, use_unk)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlpadd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfold_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeamsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras_rnn_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_unk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_unk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaxlend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0meos\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-547e53829781>\u001b[0m in \u001b[0;36mbeamsearch\u001b[0;34m(predict, start, k, maxsample, use_unk, empty, eos, temperature)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# total score for every sample is sum of -log of word prb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcand_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlive_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mcand_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_unk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_unknown_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 1 with size 0"
     ]
    }
   ],
   "source": [
    "gensamples(skips=2, batch_size=batch_size, k=10, temperature=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Data generator generates batches of inputs and outputs/labels for training. The inputs are each made from two parts. The first maxlend words are the original description, followed by `eos` followed by the headline which we want to predict, except for the last word in the headline which is always `eos` and then `empty` padding until `maxlen` words.\n",
    "\n",
    "For each, input, the output is the headline words (without the start `eos` but with the ending `eos`) padded with `empty` words up to `maxlenh` words. The output is also expanded to be y-hot encoding of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To be more realistic, the second part of the input should be the result of generation and not the original headline.\n",
    "Instead we will flip just `nflips` words to be from the generator, but even this is too hard and instead\n",
    "implement flipping in a naive way (which consumes less time.) Using the full input (description + eos + headline) generate predictions for outputs. For nflips random words from the output, replace the original word with the word with highest probability from the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def flip_headline(x, nflips=None, model=None, debug=False):\n",
    "    \"\"\"given a vectorized input (after `pad_sequences`) flip some of the words in the second half (headline)\n",
    "    with words predicted by the model\n",
    "    \"\"\"\n",
    "    if nflips is None or model is None or nflips <= 0:\n",
    "        return x\n",
    "    \n",
    "    batch_size = len(x)\n",
    "    assert np.all(x[:,maxlend] == eos)\n",
    "    probs = model.predict(x, verbose=0, batch_size=batch_size)\n",
    "    x_out = x.copy()\n",
    "    for b in range(batch_size):\n",
    "        # pick locations we want to flip\n",
    "        # 0...maxlend-1 are descriptions and should be fixed\n",
    "        # maxlend is eos and should be fixed\n",
    "        #flips = sorted(random.sample(xrange(maxlend+1,maxlen), nflips))\n",
    "        flips = sorted(random.sample(range(maxlend+1,maxlen), nflips))\n",
    "        if debug and b < debug:\n",
    "            print(b,)\n",
    "        for input_idx in flips:\n",
    "            if x[b,input_idx] == empty or x[b,input_idx] == eos:\n",
    "                continue\n",
    "            # convert from input location to label location\n",
    "            # the output at maxlend (when input is eos) is feed as input at maxlend+1\n",
    "            label_idx = input_idx - (maxlend+1)\n",
    "            prob = probs[b, label_idx]\n",
    "            w = prob.argmax()\n",
    "            if w == empty:  # replace accidental empty with oov\n",
    "                w = oov0\n",
    "            if debug and b < debug:\n",
    "                print('%s => %s'%(idx2word[x_out[b,input_idx]],idx2word[w]),)\n",
    "            x_out[b,input_idx] = w\n",
    "        if debug and b < debug:\n",
    "            print()\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_seq_labels(xds, xhs, nflips=None, model=None, debug=False):\n",
    "    \"\"\"description and hedlines are converted to padded input vectors. headlines are one-hot to label\"\"\"\n",
    "    batch_size = len(xhs)\n",
    "    assert len(xds) == batch_size\n",
    "    x = [vocab_fold(lpadd(xd)+xh) for xd,xh in zip(xds,xhs)]  # the input does not have 2nd eos\n",
    "    x = sequence.pad_sequences(x, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    x = flip_headline(x, nflips=nflips, model=model, debug=debug)\n",
    "    \n",
    "    y = np.zeros((batch_size, maxlenh, vocab_size))\n",
    "    for i, xh in enumerate(xhs):\n",
    "        xh = vocab_fold(xh) + [eos] + [empty]*maxlenh  # output does have a eos at end\n",
    "        xh = xh[:maxlenh]\n",
    "        y[i,:,:] = np_utils.to_categorical(xh, vocab_size)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen(Xd, Xh, batch_size=batch_size, nb_batches=None, nflips=None, model=None, debug=False, seed=seed):\n",
    "    \"\"\"yield batches. for training use nb_batches=None\n",
    "    for validation generate deterministic results repeating every nb_batches\n",
    "    \n",
    "    while training it is good idea to flip once in a while the values of the headlines from the\n",
    "    value taken from Xh to value generated by the model.\n",
    "    \"\"\"\n",
    "    c = nb_batches if nb_batches else 0\n",
    "    while True:\n",
    "        xds = []\n",
    "        xhs = []\n",
    "        if nb_batches and c >= nb_batches:\n",
    "            c = 0\n",
    "        #new_seed = random.randint(0, sys.maxint)\n",
    "        new_seed = random.randint(0, sys.maxsize)\n",
    "        random.seed(c+123456789+seed)\n",
    "        for b in range(batch_size):\n",
    "            t = random.randint(0,len(Xd)-1)\n",
    "\n",
    "            xd = Xd[t]\n",
    "            s = random.randint(min(maxlend,len(xd)), max(maxlend,len(xd)))\n",
    "            xds.append(xd[:s])\n",
    "            \n",
    "            xh = Xh[t]\n",
    "            s = random.randint(min(maxlenh,len(xh)), max(maxlenh,len(xh)))\n",
    "            xhs.append(xh[:s])\n",
    "\n",
    "        # undo the seeding before we yield inorder not to affect the caller\n",
    "        c+= 1\n",
    "        random.seed(new_seed)\n",
    "\n",
    "        yield conv_seq_labels(xds, xhs, nflips=nflips, model=model, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 50), (64, 25, 40000), 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = next(gen(X_train, Y_train, batch_size=batch_size))\n",
    "r[0].shape, r[1].shape, len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_gen(gen, n=5):\n",
    "    Xtr,Ytr = next(gen)\n",
    "    for i in range(n):\n",
    "        assert Xtr[i,maxlend] == eos\n",
    "        x = Xtr[i,:maxlend]\n",
    "        y = Xtr[i,maxlend:]\n",
    "        yy = Ytr[i,:]\n",
    "        yy = np.where(yy)[1]\n",
    "        prt('L',yy)\n",
    "        prt('H',y)\n",
    "        if maxlend:\n",
    "            prt('D',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:\n",
      "Ventas,\n",
      "Inc.\n",
      "Announces\n",
      "Quarterly\n",
      "Dividend\n",
      "of\n",
      "<0>^\n",
      "(VTR)\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "Ventas,\n",
      "Inc.\n",
      "Announces\n",
      "Quarterly\n",
      "Dividend\n",
      "of\n",
      "<0>^\n",
      "(VTR)\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "analysts\n",
      "have\n",
      "rated\n",
      "the\n",
      "stock\n",
      "with\n",
      "a\n",
      "hold\n",
      "rating\n",
      "and\n",
      "five\n",
      "have\n",
      "given\n",
      "a\n",
      "buy\n",
      "rating\n",
      "to\n",
      "the\n",
      "stock.\n",
      "The\n",
      "stock\n",
      "currently\n",
      "has\n",
      "a\n",
      "consensus\n",
      "\n",
      "L:\n",
      "Gaffaney\n",
      "headed\n",
      "to\n",
      "Spain\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "Gaffaney\n",
      "headed\n",
      "to\n",
      "Spain\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "read\n",
      "and\n",
      "<3>^\n",
      "At\n",
      "<0>^\n",
      "and\n",
      "out\n",
      "of\n",
      "The\n",
      "Snowden\n",
      "School\n",
      "and\n",
      "McKenna\n",
      "McKenna\n",
      "College\n",
      "<2>^\n",
      "in\n",
      "Business\n",
      "Administration\n",
      "-\n",
      "Marketing),\n",
      "he\n",
      "averaged\n",
      "<1>^\n",
      "points,\n",
      "\n",
      "L:\n",
      "1\n",
      "<0>^\n",
      "2\n",
      "injured\n",
      "In\n",
      "Sacramento\n",
      "City\n",
      "College\n",
      "shooting\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "1\n",
      "<0>^\n",
      "2\n",
      "injured\n",
      "In\n",
      "Sacramento\n",
      "City\n",
      "College\n",
      "shooting\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "say\n",
      "three\n",
      "people\n",
      "have\n",
      "been\n",
      "shot\n",
      "and\n",
      "one\n",
      "of\n",
      "them\n",
      "has\n",
      "died\n",
      "near\n",
      "a\n",
      "baseball\n",
      "field\n",
      "on\n",
      "the\n",
      "campus\n",
      "of\n",
      "Sacramento\n",
      "City\n",
      "<1>^\n",
      "Police\n",
      "say\n",
      "\n",
      "L:\n",
      "adidas\n",
      "Tubular\n",
      "X\n",
      "Arrives\n",
      "In\n",
      "Three\n",
      "New\n",
      "Colorways\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "adidas\n",
      "Tubular\n",
      "X\n",
      "Arrives\n",
      "In\n",
      "Three\n",
      "New\n",
      "Colorways\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "Colorways\n",
      "By\n",
      "Ray\n",
      "P\n",
      "-\n",
      "Sep\n",
      "14,\n",
      "2015\n",
      "0\n",
      "SHARE\n",
      "Facebook\n",
      "Twitter\n",
      "Tubular\n",
      "X\n",
      "season\n",
      "is\n",
      "here\n",
      "for\n",
      "adidas\n",
      "and\n",
      "they’re\n",
      "starting\n",
      "to\n",
      "really\n",
      "screw\n",
      "\n",
      "L:\n",
      "Jason\n",
      "<0>^\n",
      "with\n",
      "a\n",
      "stunning\n",
      "bronze\n",
      "Warmoth\n",
      "Guitar\n",
      "for\n",
      "Jason's\n",
      "collection\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "Jason\n",
      "<0>^\n",
      "with\n",
      "a\n",
      "stunning\n",
      "bronze\n",
      "Warmoth\n",
      "Guitar\n",
      "for\n",
      "Jason's\n",
      "collection\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "Warmoth\n",
      "Guitar\n",
      "Products\n",
      "for\n",
      "making\n",
      "this\n",
      "nostalgic\n",
      "guitar\n",
      "for\n",
      "me!\n",
      "When\n",
      "I\n",
      "was\n",
      "9\n",
      "years\n",
      "old,\n",
      "I\n",
      "saw\n",
      "the\n",
      "movie,\n",
      "The\n",
      "Last\n",
      "Waltz,\n",
      "about\n",
      "THE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_gen(gen(X_train, Y_train, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "test fliping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:\n",
      "Ventas,\n",
      "Inc.\n",
      "Announces\n",
      "Quarterly\n",
      "Dividend\n",
      "of\n",
      "<0>^\n",
      "(VTR)\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "Ventas,\n",
      "Inc.\n",
      "Announces\n",
      "Quarterly\n",
      "Dividend\n",
      "of\n",
      "explains\n",
      "(VTR)\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "analysts\n",
      "have\n",
      "rated\n",
      "the\n",
      "stock\n",
      "with\n",
      "a\n",
      "hold\n",
      "rating\n",
      "and\n",
      "five\n",
      "have\n",
      "given\n",
      "a\n",
      "buy\n",
      "rating\n",
      "to\n",
      "the\n",
      "stock.\n",
      "The\n",
      "stock\n",
      "currently\n",
      "has\n",
      "a\n",
      "consensus\n",
      "\n",
      "L:\n",
      "Gaffaney\n",
      "headed\n",
      "to\n",
      "Spain\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "Gaffaney\n",
      "headed\n",
      "to\n",
      "mental\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "read\n",
      "and\n",
      "<3>^\n",
      "At\n",
      "<0>^\n",
      "and\n",
      "out\n",
      "of\n",
      "The\n",
      "Snowden\n",
      "School\n",
      "and\n",
      "McKenna\n",
      "McKenna\n",
      "College\n",
      "<2>^\n",
      "in\n",
      "Business\n",
      "Administration\n",
      "-\n",
      "Marketing),\n",
      "he\n",
      "averaged\n",
      "<1>^\n",
      "points,\n",
      "\n",
      "L:\n",
      "1\n",
      "<0>^\n",
      "2\n",
      "injured\n",
      "In\n",
      "Sacramento\n",
      "City\n",
      "College\n",
      "shooting\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "1\n",
      "non-\n",
      "2\n",
      "injured\n",
      "In\n",
      "Sacramento\n",
      "City\n",
      "College\n",
      "shooting\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "say\n",
      "three\n",
      "people\n",
      "have\n",
      "been\n",
      "shot\n",
      "and\n",
      "one\n",
      "of\n",
      "them\n",
      "has\n",
      "died\n",
      "near\n",
      "a\n",
      "baseball\n",
      "field\n",
      "on\n",
      "the\n",
      "campus\n",
      "of\n",
      "Sacramento\n",
      "City\n",
      "<1>^\n",
      "Police\n",
      "say\n",
      "\n",
      "L:\n",
      "adidas\n",
      "Tubular\n",
      "X\n",
      "Arrives\n",
      "In\n",
      "Three\n",
      "New\n",
      "Colorways\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "adidas\n",
      "Tubular\n",
      "thaw\n",
      "Arrives\n",
      "In\n",
      "Three\n",
      "New\n",
      "Colorways\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "Colorways\n",
      "By\n",
      "Ray\n",
      "P\n",
      "-\n",
      "Sep\n",
      "14,\n",
      "2015\n",
      "0\n",
      "SHARE\n",
      "Facebook\n",
      "Twitter\n",
      "Tubular\n",
      "X\n",
      "season\n",
      "is\n",
      "here\n",
      "for\n",
      "adidas\n",
      "and\n",
      "they’re\n",
      "starting\n",
      "to\n",
      "really\n",
      "screw\n",
      "\n",
      "L:\n",
      "Jason\n",
      "<0>^\n",
      "with\n",
      "a\n",
      "stunning\n",
      "bronze\n",
      "Warmoth\n",
      "Guitar\n",
      "for\n",
      "Jason's\n",
      "collection\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "Jason\n",
      "<0>^\n",
      "with\n",
      "Era\n",
      "stunning\n",
      "bronze\n",
      "Warmoth\n",
      "Guitar\n",
      "for\n",
      "PGA\n",
      "collection\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "Warmoth\n",
      "Guitar\n",
      "Products\n",
      "for\n",
      "making\n",
      "this\n",
      "nostalgic\n",
      "guitar\n",
      "for\n",
      "me!\n",
      "When\n",
      "I\n",
      "was\n",
      "9\n",
      "years\n",
      "old,\n",
      "I\n",
      "saw\n",
      "the\n",
      "movie,\n",
      "The\n",
      "Last\n",
      "Waltz,\n",
      "about\n",
      "THE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_gen(gen(X_train, Y_train, nflips=6, model=model, debug=False, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "valgen = gen(X_test, Y_test,nb_batches=3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "check that valgen repeats itself after nb_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:\n",
      "In\n",
      "Coimbatore\n",
      "Today\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "In\n",
      "Coimbatore\n",
      "Today\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "City\n",
      "Tower,\n",
      "<1>^\n",
      "10\n",
      "a.m.\n",
      "Vijaya\n",
      "<3>^\n",
      "Vattam:\n",
      "<0>^\n",
      "Sidhapudur\n",
      "Government\n",
      "High\n",
      "School,\n",
      "10\n",
      "a.m.\n",
      "Dr.\n",
      "N.G.P\n",
      "Arts\n",
      "and\n",
      "Science\n",
      "<2>^\n",
      "Parent\n",
      "Teacher\n",
      "Association\n",
      "meeting,\n",
      "\n",
      "L:\n",
      "Hunt\n",
      "for\n",
      "3\n",
      "suspects\n",
      "in\n",
      "Illinois\n",
      "officer's\n",
      "death\n",
      "continues\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "Hunt\n",
      "for\n",
      "3\n",
      "suspects\n",
      "in\n",
      "Illinois\n",
      "officer's\n",
      "death\n",
      "continues\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "of\n",
      "a\n",
      "popular\n",
      "veteran\n",
      "police\n",
      "officer\n",
      "in\n",
      "a\n",
      "small\n",
      "northern\n",
      "Illinois\n",
      "community.\n",
      "Lake\n",
      "County\n",
      "Sheriff's\n",
      "Office\n",
      "spokesman\n",
      "Sgt.\n",
      "Christopher\n",
      "Covelli\n",
      "said\n",
      "hundreds\n",
      "of\n",
      "officers\n",
      "were\n",
      "\n",
      "L:\n",
      "Butter\n",
      "“Margarine\n",
      "Fingers”\n",
      "Ad\n",
      "<0>^\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "Butter\n",
      "“Margarine\n",
      "Fingers”\n",
      "Ad\n",
      "<2>^\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "a\n",
      "<1>^\n",
      "expression,\n",
      "indicating\n",
      "that\n",
      "<3>^\n",
      "fingers”\n",
      "does\n",
      "not\n",
      "sound\n",
      "at\n",
      "all\n",
      "<0>^\n",
      "Then\n",
      "they\n",
      "decide\n",
      "together\n",
      "to\n",
      "use\n",
      "butter\n",
      "in\n",
      "the\n",
      "dish\n",
      "they\n",
      "are\n",
      "\n",
      "L:\n",
      "In\n",
      "Coimbatore\n",
      "Today\n",
      "~\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "H:\n",
      "~\n",
      "In\n",
      "Coimbatore\n",
      "Today\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "D:\n",
      "City\n",
      "Tower,\n",
      "<1>^\n",
      "10\n",
      "a.m.\n",
      "Vijaya\n",
      "<3>^\n",
      "Vattam:\n",
      "<0>^\n",
      "Sidhapudur\n",
      "Government\n",
      "High\n",
      "School,\n",
      "10\n",
      "a.m.\n",
      "Dr.\n",
      "N.G.P\n",
      "Arts\n",
      "and\n",
      "Science\n",
      "<2>^\n",
      "Parent\n",
      "Teacher\n",
      "Association\n",
      "meeting,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    test_gen(valgen, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "traingen = gen(X_train, Y_train, batch_size=batch_size, nflips=nflips, model=model)\n",
    "valgen = gen(X_test, Y_test, nb_batches=nb_val_samples//batch_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 50), (64, 25, 40000), 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = next(traingen)\n",
    "r[0].shape, r[1].shape, len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,25,40000]\n\t [[Node: gradients/mul_1_grad/mul_1 = Mul[T=DT_FLOAT, _class=[\"loc:@mul_1\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_activation_1_target_0/_241, gradients/Sum_5_grad/Tile)]]\n\t [[Node: gradients/while_1/Select_grad/Select/_601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5969_gradients/while_1/Select_grad/Select\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/while_1/add_7_grad/BroadcastGradientArgs/StackPop/_192)]]\n\nCaused by op 'gradients/mul_1_grad/mul_1', defined at:\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-85-a4a1878bd49b>\", line 4, in <module>\n    nb_epoch=1, validation_data=valgen, nb_val_samples=nb_val_samples\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py\", line 935, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\", line 1454, in fit_generator\n    self._make_train_function()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\", line 760, in _make_train_function\n    self.total_loss)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/optimizers.py\", line 416, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/optimizers.py\", line 82, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1968, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\n    in_grads = grad_fn(op, *out_grads)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\", line 614, in _MulGrad\n    array_ops.reshape(math_ops.reduce_sum(x * grad, ry), sy))\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1105, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1625, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'mul_1', defined at:\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 16 identical lines from previous traceback]\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-57-70b7e23fa581>\", line 3, in <module>\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py\", line 594, in compile\n    **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\", line 667, in compile\n    sample_weight, mask)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\", line 318, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/objectives.py\", line 37, in categorical_crossentropy\n    return K.categorical_crossentropy(y_pred, y_true)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2389, in categorical_crossentropy\n    return - tf.reduce_sum(target * tf.log(output),\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1105, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1625, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,25,40000]\n\t [[Node: gradients/mul_1_grad/mul_1 = Mul[T=DT_FLOAT, _class=[\"loc:@mul_1\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_activation_1_target_0/_241, gradients/Sum_5_grad/Tile)]]\n\t [[Node: gradients/while_1/Select_grad/Select/_601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5969_gradients/while_1/Select_grad/Select\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/while_1/add_7_grad/BroadcastGradientArgs/StackPop/_192)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,25,40000]\n\t [[Node: gradients/mul_1_grad/mul_1 = Mul[T=DT_FLOAT, _class=[\"loc:@mul_1\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_activation_1_target_0/_241, gradients/Sum_5_grad/Tile)]]\n\t [[Node: gradients/while_1/Select_grad/Select/_601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5969_gradients/while_1/Select_grad/Select\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/while_1/add_7_grad/BroadcastGradientArgs/StackPop/_192)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-a4a1878bd49b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     h = model.fit_generator(traingen, samples_per_epoch=nb_train_samples,\n\u001b[0;32m----> 4\u001b[0;31m                         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                            )\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#for k,v in h.history.iteritems():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1556\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,25,40000]\n\t [[Node: gradients/mul_1_grad/mul_1 = Mul[T=DT_FLOAT, _class=[\"loc:@mul_1\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_activation_1_target_0/_241, gradients/Sum_5_grad/Tile)]]\n\t [[Node: gradients/while_1/Select_grad/Select/_601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5969_gradients/while_1/Select_grad/Select\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/while_1/add_7_grad/BroadcastGradientArgs/StackPop/_192)]]\n\nCaused by op 'gradients/mul_1_grad/mul_1', defined at:\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-85-a4a1878bd49b>\", line 4, in <module>\n    nb_epoch=1, validation_data=valgen, nb_val_samples=nb_val_samples\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py\", line 935, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\", line 1454, in fit_generator\n    self._make_train_function()\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\", line 760, in _make_train_function\n    self.total_loss)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/optimizers.py\", line 416, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/optimizers.py\", line 82, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1968, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\n    in_grads = grad_fn(op, *out_grads)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\", line 614, in _MulGrad\n    array_ops.reshape(math_ops.reduce_sum(x * grad, ry), sy))\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1105, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1625, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'mul_1', defined at:\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 16 identical lines from previous traceback]\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-57-70b7e23fa581>\", line 3, in <module>\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py\", line 594, in compile\n    **kwargs)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\", line 667, in compile\n    sample_weight, mask)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\", line 318, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/objectives.py\", line 37, in categorical_crossentropy\n    return K.categorical_crossentropy(y_pred, y_true)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2389, in categorical_crossentropy\n    return - tf.reduce_sum(target * tf.log(output),\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1105, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1625, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,25,40000]\n\t [[Node: gradients/mul_1_grad/mul_1 = Mul[T=DT_FLOAT, _class=[\"loc:@mul_1\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_activation_1_target_0/_241, gradients/Sum_5_grad/Tile)]]\n\t [[Node: gradients/while_1/Select_grad/Select/_601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5969_gradients/while_1/Select_grad/Select\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/while_1/add_7_grad/BroadcastGradientArgs/StackPop/_192)]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(500):\n",
    "    print('Iteration', iteration)\n",
    "    h = model.fit_generator(traingen, samples_per_epoch=nb_train_samples,\n",
    "                        nb_epoch=1, validation_data=valgen, nb_val_samples=nb_val_samples\n",
    "                           )\n",
    "    #for k,v in h.history.iteritems():\n",
    "    for k,v in h.history.iteritems():\n",
    "        history[k] = history.get(k,[]) + v\n",
    "    with open('data/%s.history.pkl'%FN,'wb') as fp:\n",
    "        pickle.dump(history,fp,-1)\n",
    "    model.save_weights('data/%s.hdf5'%FN, overwrite=True)\n",
    "    gensamples(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
